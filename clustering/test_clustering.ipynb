{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN, HDBSCAN, OPTICS\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "\n",
    "# Important for conversion of lat-long based distance to meters\n",
    "RADIUS_OF_EARTH_AT_SPACE_NEEDLE = 6366.512563943 # km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def extract_yearly_data(df, dirname, base_filename, year_range):\n",
    "    dirpath = os.path.join(os.getcwd(), dirname)\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "    path = os.path.join(dirpath, base_filename)\n",
    "    for year in year_range:\n",
    "        year_df = df.loc[df[\"Year\"] == year]\n",
    "        year_df.to_csv(path + \"_year_\" + str(year) + \".csv\", index=False)\n",
    "    return\n",
    "\n",
    "\n",
    "def meters_to_hav(meters, R=RADIUS_OF_EARTH_AT_SPACE_NEEDLE):\n",
    "    \"\"\"Converts a distance to haversine distance\"\"\"\n",
    "    hav = meters / (R * 1000)\n",
    "    return hav\n",
    "\n",
    "\n",
    "def get_range(df, col):\n",
    "    min_val = df[col].min()\n",
    "    max_val = df[col].max()\n",
    "    return min_val, max_val\n",
    "\n",
    "\n",
    "def linearly_interpolate(x, old_interval, new_interval):\n",
    "    a, b = old_interval\n",
    "    c, d = new_interval\n",
    "    new_x = c + (x - a) * ((d - c) / b - a)\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance metrics I was playing with\n",
    "def euclidean_dist(x, y):\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "\n",
    "def haversine_np(lon1, lat1, lon2, lat2, R=RADIUS_OF_EARTH_AT_SPACE_NEEDLE):\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = R * c\n",
    "    return km\n",
    "\n",
    "\n",
    "def linearized_haversine(a, b, R=RADIUS_OF_EARTH_AT_SPACE_NEEDLE):\n",
    "    a_rad = a * (2 * np.pi / 360)\n",
    "    b_rad = b * (2 * np.pi / 360)\n",
    "    x_1, y_1 = a_rad\n",
    "    x_2, y_2 = b_rad\n",
    "    delta_x = R * np.cos(y_1) * (x_2 - x_1)\n",
    "    delta_y = R * (y_2 - y_1)\n",
    "    return np.sqrt(delta_x**2 + delta_y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the crime data\n",
    "crime_df = pd.read_csv(\"SPD_Crime_Data__2008-Present.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the crimes with missing time, category, or spatial data\n",
    "crime_df = crime_df.dropna(\n",
    "    axis=0,\n",
    "    how=\"any\",\n",
    "    subset=[\"Offense Start DateTime\", \"Offense Parent Group\", \"Longitude\", \"Latitude\"],\n",
    "    inplace=False,\n",
    ")\n",
    "\n",
    "# Filter crimes with wacky position data\n",
    "crime_df = crime_df.loc[(crime_df[\"Latitude\"] > 47) & (crime_df[\"Latitude\"] < 48) ]\n",
    "crime_df = crime_df.loc[(crime_df[\"Longitude\"] > -123) & (crime_df[\"Longitude\"] < -122)]\n",
    "\n",
    "# Drop report information to reduce data size\n",
    "crime_df = crime_df.drop(\n",
    "    axis=1, columns=[\"Report Number\", \"Report DateTime\"], inplace=False\n",
    ")\n",
    "\n",
    "# Convert time to datetime column\n",
    "crime_df[\"Offense Start DateTime\"] = pd.to_datetime(crime_df[\"Offense Start DateTime\"])\n",
    "\n",
    "# Extract offense year, month, day, and time of day\n",
    "crime_df['Year'] = crime_df['Offense Start DateTime'].dt.year\n",
    "crime_df['Month'] = crime_df['Offense Start DateTime'].dt.month.astype(int)\n",
    "crime_df['Day'] = crime_df['Offense Start DateTime'].dt.dayofweek.astype(int)\n",
    "crime_df['Time'] = crime_df['Offense Start DateTime'].dt.time\n",
    "\n",
    "# Filter to crimes since 2008\n",
    "crime_df = crime_df.loc[crime_df[\"Year\"] >= 2008]\n",
    "\n",
    "# Express lat and long in radians for haversine metric\n",
    "crime_df[\"long_rad\"] = crime_df[\"Longitude\"].apply(np.radians)\n",
    "crime_df[\"lat_rad\"] = crime_df[\"Latitude\"].apply(np.radians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Offense ID</th>\n",
       "      <th>Offense Start DateTime</th>\n",
       "      <th>Offense End DateTime</th>\n",
       "      <th>Group A B</th>\n",
       "      <th>Crime Against Category</th>\n",
       "      <th>Offense Parent Group</th>\n",
       "      <th>Offense</th>\n",
       "      <th>Offense Code</th>\n",
       "      <th>Precinct</th>\n",
       "      <th>Sector</th>\n",
       "      <th>...</th>\n",
       "      <th>MCPP</th>\n",
       "      <th>100 Block Address</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time</th>\n",
       "      <th>long_rad</th>\n",
       "      <th>lat_rad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12605873663</td>\n",
       "      <td>2020-02-05 10:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>SOCIETY</td>\n",
       "      <td>DRUG/NARCOTIC OFFENSES</td>\n",
       "      <td>Drug/Narcotic Violations</td>\n",
       "      <td>35A</td>\n",
       "      <td>W</td>\n",
       "      <td>Q</td>\n",
       "      <td>...</td>\n",
       "      <td>MAGNOLIA</td>\n",
       "      <td>32XX BLOCK OF 23RD AVE W</td>\n",
       "      <td>-122.385974</td>\n",
       "      <td>47.649387</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10:10:00</td>\n",
       "      <td>-2.136038</td>\n",
       "      <td>0.831639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12605598696</td>\n",
       "      <td>2020-02-03 08:00:00</td>\n",
       "      <td>02/04/2020 08:00:00 AM</td>\n",
       "      <td>A</td>\n",
       "      <td>PROPERTY</td>\n",
       "      <td>LARCENY-THEFT</td>\n",
       "      <td>Theft of Motor Vehicle Parts or Accessories</td>\n",
       "      <td>23G</td>\n",
       "      <td>N</td>\n",
       "      <td>J</td>\n",
       "      <td>...</td>\n",
       "      <td>ROOSEVELT/RAVENNA</td>\n",
       "      <td>63XX BLOCK OF 5TH AVE NE</td>\n",
       "      <td>-122.323399</td>\n",
       "      <td>47.675118</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>-2.134946</td>\n",
       "      <td>0.832088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12605567653</td>\n",
       "      <td>2020-02-02 20:30:00</td>\n",
       "      <td>02/02/2020 09:30:00 PM</td>\n",
       "      <td>A</td>\n",
       "      <td>PROPERTY</td>\n",
       "      <td>ROBBERY</td>\n",
       "      <td>Robbery</td>\n",
       "      <td>120</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>...</td>\n",
       "      <td>ROOSEVELT/RAVENNA</td>\n",
       "      <td>26TH AVE NE / NE BLAKELEY ST</td>\n",
       "      <td>-122.299552</td>\n",
       "      <td>47.666384</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>20:30:00</td>\n",
       "      <td>-2.134530</td>\n",
       "      <td>0.831935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12605174036</td>\n",
       "      <td>2020-02-05 01:17:00</td>\n",
       "      <td>02/05/2020 02:21:00 AM</td>\n",
       "      <td>A</td>\n",
       "      <td>PROPERTY</td>\n",
       "      <td>DESTRUCTION/DAMAGE/VANDALISM OF PROPERTY</td>\n",
       "      <td>Destruction/Damage/Vandalism of Property</td>\n",
       "      <td>290</td>\n",
       "      <td>W</td>\n",
       "      <td>Q</td>\n",
       "      <td>...</td>\n",
       "      <td>MAGNOLIA</td>\n",
       "      <td>22XX BLOCK OF W RAYE ST</td>\n",
       "      <td>-122.384865</td>\n",
       "      <td>47.642927</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>01:17:00</td>\n",
       "      <td>-2.136019</td>\n",
       "      <td>0.831526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12605081469</td>\n",
       "      <td>2020-02-05 00:51:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>SOCIETY</td>\n",
       "      <td>DRIVING UNDER THE INFLUENCE</td>\n",
       "      <td>Driving Under the Influence</td>\n",
       "      <td>90D</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>BALLARD SOUTH</td>\n",
       "      <td>NW 46TH ST / 8TH AVE NW</td>\n",
       "      <td>-122.366195</td>\n",
       "      <td>47.662193</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>00:51:21</td>\n",
       "      <td>-2.135693</td>\n",
       "      <td>0.831862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Offense ID Offense Start DateTime    Offense End DateTime Group A B  \\\n",
       "0  12605873663    2020-02-05 10:10:00                     NaN         A   \n",
       "1  12605598696    2020-02-03 08:00:00  02/04/2020 08:00:00 AM         A   \n",
       "2  12605567653    2020-02-02 20:30:00  02/02/2020 09:30:00 PM         A   \n",
       "3  12605174036    2020-02-05 01:17:00  02/05/2020 02:21:00 AM         A   \n",
       "4  12605081469    2020-02-05 00:51:21                     NaN         B   \n",
       "\n",
       "  Crime Against Category                      Offense Parent Group  \\\n",
       "0                SOCIETY                    DRUG/NARCOTIC OFFENSES   \n",
       "1               PROPERTY                             LARCENY-THEFT   \n",
       "2               PROPERTY                                   ROBBERY   \n",
       "3               PROPERTY  DESTRUCTION/DAMAGE/VANDALISM OF PROPERTY   \n",
       "4                SOCIETY               DRIVING UNDER THE INFLUENCE   \n",
       "\n",
       "                                       Offense Offense Code Precinct Sector  \\\n",
       "0                     Drug/Narcotic Violations          35A        W      Q   \n",
       "1  Theft of Motor Vehicle Parts or Accessories          23G        N      J   \n",
       "2                                      Robbery          120        N      U   \n",
       "3     Destruction/Damage/Vandalism of Property          290        W      Q   \n",
       "4                  Driving Under the Influence          90D        N      B   \n",
       "\n",
       "   ...               MCPP             100 Block Address   Longitude  \\\n",
       "0  ...           MAGNOLIA      32XX BLOCK OF 23RD AVE W -122.385974   \n",
       "1  ...  ROOSEVELT/RAVENNA      63XX BLOCK OF 5TH AVE NE -122.323399   \n",
       "2  ...  ROOSEVELT/RAVENNA  26TH AVE NE / NE BLAKELEY ST -122.299552   \n",
       "3  ...           MAGNOLIA       22XX BLOCK OF W RAYE ST -122.384865   \n",
       "4  ...      BALLARD SOUTH       NW 46TH ST / 8TH AVE NW -122.366195   \n",
       "\n",
       "    Latitude  Year  Month  Day      Time  long_rad   lat_rad  \n",
       "0  47.649387  2020      2    2  10:10:00 -2.136038  0.831639  \n",
       "1  47.675118  2020      2    0  08:00:00 -2.134946  0.832088  \n",
       "2  47.666384  2020      2    6  20:30:00 -2.134530  0.831935  \n",
       "3  47.642927  2020      2    2  01:17:00 -2.136019  0.831526  \n",
       "4  47.662193  2020      2    2  00:51:21 -2.135693  0.831862  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create yearly extracts if you want\n",
    "extract_yearly_data(crime_df, \"yearly_extracts\", \"SPD_Crime_Data\", range(2008, 2025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "crime_df.to_csv(\"cleaned_SPD_Crime_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking range of lat and long columns\n",
    "min_long, max_long = get_range(crime_df, \"Longitude\")\n",
    "min_lat, max_lat = get_range(crime_df, \"Latitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15724.679469803265, 36253.28281720292)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_range = 1000 * haversine_np(min_long, min_lat, max_long, min_lat)\n",
    "y_range = 1000 * haversine_np(min_long, min_lat, min_long, max_lat)\n",
    "\n",
    "x_range, y_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15724.68421289776, 36253.28281720292)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A linearized version introduces very little error, if we need it\n",
    "x_range_lin = 1000 * linearized_haversine(np.array([min_long, min_lat]), np.array([max_long, min_lat]))\n",
    "y_range_lin = 1000 * linearized_haversine(np.array([min_long, min_lat]), np.array([min_long, max_lat]))\n",
    "\n",
    "x_range_lin, y_range_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Offense ID</th>\n",
       "      <th>Offense Start DateTime</th>\n",
       "      <th>Offense End DateTime</th>\n",
       "      <th>Group A B</th>\n",
       "      <th>Crime Against Category</th>\n",
       "      <th>Offense Parent Group</th>\n",
       "      <th>Offense</th>\n",
       "      <th>Offense Code</th>\n",
       "      <th>Precinct</th>\n",
       "      <th>Sector</th>\n",
       "      <th>...</th>\n",
       "      <th>MCPP</th>\n",
       "      <th>100 Block Address</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time</th>\n",
       "      <th>long_rad</th>\n",
       "      <th>lat_rad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1020342</th>\n",
       "      <td>41318760607</td>\n",
       "      <td>2023-01-18 00:00:00</td>\n",
       "      <td>01/18/2023 11:59:00 PM</td>\n",
       "      <td>A</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>ASSAULT OFFENSES</td>\n",
       "      <td>Intimidation</td>\n",
       "      <td>13C</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>CAPITOL HILL</td>\n",
       "      <td>6XX BLOCK OF HARVARD AVE E</td>\n",
       "      <td>-122.321983</td>\n",
       "      <td>47.624694</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>-2.134921</td>\n",
       "      <td>0.831208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020395</th>\n",
       "      <td>41315958431</td>\n",
       "      <td>2023-01-30 10:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>SOCIETY</td>\n",
       "      <td>TRESPASS OF REAL PROPERTY</td>\n",
       "      <td>Trespass of Real Property</td>\n",
       "      <td>90J</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>CAPITOL HILL</td>\n",
       "      <td>14XX BLOCK OF E HOWELL ST</td>\n",
       "      <td>-122.313516</td>\n",
       "      <td>47.617626</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10:30:00</td>\n",
       "      <td>-2.134774</td>\n",
       "      <td>0.831084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020446</th>\n",
       "      <td>41312435583</td>\n",
       "      <td>2023-01-29 21:40:00</td>\n",
       "      <td>01/29/2023 10:12:00 PM</td>\n",
       "      <td>B</td>\n",
       "      <td>SOCIETY</td>\n",
       "      <td>DRIVING UNDER THE INFLUENCE</td>\n",
       "      <td>Driving Under the Influence</td>\n",
       "      <td>90D</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>CAPITOL HILL</td>\n",
       "      <td>14XX BLOCK OF 11TH AVE</td>\n",
       "      <td>-122.318132</td>\n",
       "      <td>47.613513</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>21:40:00</td>\n",
       "      <td>-2.134854</td>\n",
       "      <td>0.831013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020536</th>\n",
       "      <td>41288788167</td>\n",
       "      <td>2023-01-28 19:20:00</td>\n",
       "      <td>01/29/2023 03:20:00 AM</td>\n",
       "      <td>A</td>\n",
       "      <td>PROPERTY</td>\n",
       "      <td>LARCENY-THEFT</td>\n",
       "      <td>Theft From Building</td>\n",
       "      <td>23D</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>CAPITOL HILL</td>\n",
       "      <td>1XX BLOCK OF 10TH AVE E</td>\n",
       "      <td>-122.319530</td>\n",
       "      <td>47.619333</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>19:20:00</td>\n",
       "      <td>-2.134879</td>\n",
       "      <td>0.831114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020545</th>\n",
       "      <td>41288762898</td>\n",
       "      <td>2023-01-28 02:00:00</td>\n",
       "      <td>01/28/2023 02:01:00 AM</td>\n",
       "      <td>A</td>\n",
       "      <td>PROPERTY</td>\n",
       "      <td>LARCENY-THEFT</td>\n",
       "      <td>Theft From Building</td>\n",
       "      <td>23D</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>CAPITOL HILL</td>\n",
       "      <td>15XX BLOCK OF 11TH AVE</td>\n",
       "      <td>-122.318150</td>\n",
       "      <td>47.614674</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>-2.134854</td>\n",
       "      <td>0.831033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Offense ID Offense Start DateTime    Offense End DateTime Group A B  \\\n",
       "1020342  41318760607    2023-01-18 00:00:00  01/18/2023 11:59:00 PM         A   \n",
       "1020395  41315958431    2023-01-30 10:30:00                     NaN         B   \n",
       "1020446  41312435583    2023-01-29 21:40:00  01/29/2023 10:12:00 PM         B   \n",
       "1020536  41288788167    2023-01-28 19:20:00  01/29/2023 03:20:00 AM         A   \n",
       "1020545  41288762898    2023-01-28 02:00:00  01/28/2023 02:01:00 AM         A   \n",
       "\n",
       "        Crime Against Category         Offense Parent Group  \\\n",
       "1020342                 PERSON             ASSAULT OFFENSES   \n",
       "1020395                SOCIETY    TRESPASS OF REAL PROPERTY   \n",
       "1020446                SOCIETY  DRIVING UNDER THE INFLUENCE   \n",
       "1020536               PROPERTY                LARCENY-THEFT   \n",
       "1020545               PROPERTY                LARCENY-THEFT   \n",
       "\n",
       "                             Offense Offense Code Precinct Sector  ...  \\\n",
       "1020342                 Intimidation          13C        E      E  ...   \n",
       "1020395    Trespass of Real Property          90J        E      C  ...   \n",
       "1020446  Driving Under the Influence          90D        E      E  ...   \n",
       "1020536          Theft From Building          23D        E      E  ...   \n",
       "1020545          Theft From Building          23D        E      E  ...   \n",
       "\n",
       "                 MCPP           100 Block Address   Longitude   Latitude  \\\n",
       "1020342  CAPITOL HILL  6XX BLOCK OF HARVARD AVE E -122.321983  47.624694   \n",
       "1020395  CAPITOL HILL   14XX BLOCK OF E HOWELL ST -122.313516  47.617626   \n",
       "1020446  CAPITOL HILL      14XX BLOCK OF 11TH AVE -122.318132  47.613513   \n",
       "1020536  CAPITOL HILL     1XX BLOCK OF 10TH AVE E -122.319530  47.619333   \n",
       "1020545  CAPITOL HILL      15XX BLOCK OF 11TH AVE -122.318150  47.614674   \n",
       "\n",
       "         Year  Month  Day      Time  long_rad   lat_rad  \n",
       "1020342  2023      1    2  00:00:00 -2.134921  0.831208  \n",
       "1020395  2023      1    0  10:30:00 -2.134774  0.831084  \n",
       "1020446  2023      1    6  21:40:00 -2.134854  0.831013  \n",
       "1020536  2023      1    5  19:20:00 -2.134879  0.831114  \n",
       "1020545  2023      1    5  02:00:00 -2.134854  0.831033  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test runs on cap hill in 2023\n",
    "cap_hill_23 = crime_df.loc[\n",
    "    (crime_df[\"Year\"] == 2023) & (crime_df[\"MCPP\"] == \"CAPITOL HILL\")\n",
    "]\n",
    "cap_hill_23.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.        , 1009.45075617, 1275.44504381, ...,  343.80890441,\n",
       "         343.80890441,  341.87047085],\n",
       "       [1009.45075617,    0.        ,  573.07081297, ..., 1266.67123412,\n",
       "        1266.67123412, 1114.80616356],\n",
       "       [1275.44504381,  573.07081297,    0.        , ..., 1599.70320173,\n",
       "        1599.70320173, 1220.48001123],\n",
       "       ...,\n",
       "       [ 343.80890441, 1266.67123412, 1599.70320173, ...,    0.        ,\n",
       "           0.        ,  618.30479661],\n",
       "       [ 343.80890441, 1266.67123412, 1599.70320173, ...,    0.        ,\n",
       "           0.        ,  618.30479661],\n",
       "       [ 341.87047085, 1114.80616356, 1220.48001123, ...,  618.30479661,\n",
       "         618.30479661,    0.        ]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test precomputing distance matrix---it's fast, which is good\n",
    "latlong = cap_hill_23[[\"lat_rad\", \"long_rad\"]].to_numpy()\n",
    "distances = haversine_distances(latlong)\n",
    "distances * (RADIUS_OF_EARTH_AT_SPACE_NEEDLE * 1000) # Approx distance in meters between crimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping of crime types\n",
    "1. We need to group the crime types somehow. I haven't done it yet though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some interest groups in the future\n",
    "assault_group = [\"ASSAULT OFFENSES\"]\n",
    "theft_group = [\"LARCENY-THEFT\", \"BURGLARY/BREAKING&ENTERING\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan\n",
    "1. GridSearch---store every labeling in output dataframe for comparison in Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dbscans(X, df, supports, eps_meters=125):\n",
    "    \"\"\"DBSCAN grid search -> df + summaries\n",
    "\n",
    "    Labels stored in output. Write to disk for comparison in Tableau.\n",
    "    We need to fix epsilon small (100 meters) to constrain cluster size.\"\"\"\n",
    "    output_df = df.copy()\n",
    "    run_summaries = []\n",
    "\n",
    "    total_crime = len(X)\n",
    "    eps = meters_to_hav(eps_meters)\n",
    "\n",
    "    for min_samples in supports:\n",
    "        print(f\"DBSCAN clustering with eps={eps_meters}m, min_samples={min_samples}\")\n",
    "        # Cluster the data and extract the labels\n",
    "        colname = \"db_cluster_labels_eps=\" + str(eps_meters) + \"_ms=\" + str(min_samples)\n",
    "        db = DBSCAN(eps=eps, min_samples=min_samples, metric=\"haversine\").fit(X)\n",
    "        labels_db = db.labels_\n",
    "        # Count clusters and noise\n",
    "        num_clusters_ = len(set(labels_db)) - (1 if -1 in labels_db else 0)\n",
    "        num_noise_ = list(labels_db).count(-1)\n",
    "        percent_clustered = (total_crime - num_noise_) / total_crime\n",
    "        print(\"Estimated number of clusters: %d\" % num_clusters_)\n",
    "        print(\"Estimated number of noise points: %d\" % num_noise_)\n",
    "        print(f\"Estimated percentage of crime captured: {percent_clustered}\\n\")\n",
    "        summary = {\n",
    "            \"type\": \"DBSCAN\",\n",
    "            \"model\": db,\n",
    "            \"params\": (eps_meters, min_samples),\n",
    "            \"num_clusters\": num_clusters_,\n",
    "            \"num_noise\": num_noise_,\n",
    "            \"percent_clustered\": percent_clustered,\n",
    "        }\n",
    "        # Save the labels in the output df\n",
    "        run_summaries.append(summary)\n",
    "        output_df[colname] = labels_db\n",
    "    return output_df, run_summaries\n",
    "\n",
    "\n",
    "def run_optics(X, df, supports, eps_meters=125):\n",
    "    \"\"\"OPTICS grid search -> df + summaries\n",
    "\n",
    "    Labels stored in output. Write to disk for comparison in Tableau.\n",
    "    Similarly, we need to fix a small neighborhood size to limit size.\"\"\"\n",
    "    output_df = df.copy()\n",
    "    run_summaries = []\n",
    "\n",
    "    total_crime = len(X)\n",
    "    eps = meters_to_hav(eps_meters)\n",
    "\n",
    "    for xi in xis:\n",
    "        for ms in supports:\n",
    "            print(f\"OPTICS clustering with xi={xi}, min_samples={ms}\")\n",
    "            # Cluster the data and extract the labels\n",
    "            colname = \"op_cluster_labels_xi=\" + str(xi) + \"_ms=\" + str(ms)\n",
    "            op = OPTICS(eps=xi, min_samples=ms, metric=\"haversine\").fit(X)\n",
    "            labels_op = op.labels_\n",
    "            # Count clusters and noise\n",
    "            n_clusters_ = len(set(labels_op)) - (1 if -1 in labels_op else 0)\n",
    "            n_noise_ = list(labels_op).count(-1)\n",
    "            print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "            print(\"Estimated number of noise points: %d\" % n_noise_)\n",
    "            # Save labels in the output df\n",
    "            output_df[colname] = labels_op\n",
    "    return output_df\n",
    "\n",
    "\n",
    "def run_hdbscans(min_size, cluster_selection):\n",
    "    \"\"\"HDBSCAN grid search -> df\n",
    "\n",
    "    Labels stored in output. Write to disk for comparison in Tableau.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cap_hill_23[[\"Latitude\", \"Longitude\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN clustering with eps=100m, min_samples=15\n",
      "Estimated number of clusters: 66\n",
      "Estimated number of noise points: 1937\n",
      "Estimated percentage of crime captured: 0.4906652642650539\n",
      "\n",
      "DBSCAN clustering with eps=100m, min_samples=20\n",
      "Estimated number of clusters: 40\n",
      "Estimated number of noise points: 2373\n",
      "Estimated percentage of crime captured: 0.3760189324217723\n",
      "\n",
      "DBSCAN clustering with eps=100m, min_samples=25\n",
      "Estimated number of clusters: 25\n",
      "Estimated number of noise points: 2700\n",
      "Estimated percentage of crime captured: 0.2900341835393111\n",
      "\n",
      "DBSCAN clustering with eps=100m, min_samples=30\n",
      "Estimated number of clusters: 19\n",
      "Estimated number of noise points: 2857\n",
      "Estimated percentage of crime captured: 0.24875098606363397\n",
      "\n",
      "DBSCAN clustering with eps=100m, min_samples=35\n",
      "Estimated number of clusters: 13\n",
      "Estimated number of noise points: 3051\n",
      "Estimated percentage of crime captured: 0.1977386273994215\n",
      "\n",
      "DBSCAN clustering with eps=100m, min_samples=40\n",
      "Estimated number of clusters: 10\n",
      "Estimated number of noise points: 3165\n",
      "Estimated percentage of crime captured: 0.16776229292663686\n",
      "\n",
      "DBSCAN clustering with eps=100m, min_samples=45\n",
      "Estimated number of clusters: 8\n",
      "Estimated number of noise points: 3249\n",
      "Estimated percentage of crime captured: 0.14567446752563765\n",
      "\n",
      "DBSCAN clustering with eps=100m, min_samples=50\n",
      "Estimated number of clusters: 8\n",
      "Estimated number of noise points: 3249\n",
      "Estimated percentage of crime captured: 0.14567446752563765\n",
      "\n",
      "DBSCAN clustering with eps=100m, min_samples=55\n",
      "Estimated number of clusters: 7\n",
      "Estimated number of noise points: 3299\n",
      "Estimated percentage of crime captured: 0.13252695240599527\n",
      "\n",
      "DBSCAN clustering with eps=100m, min_samples=60\n",
      "Estimated number of clusters: 5\n",
      "Estimated number of noise points: 3415\n",
      "Estimated percentage of crime captured: 0.10202471732842493\n",
      "\n",
      "DBSCAN clustering with eps=100m, min_samples=65\n",
      "Estimated number of clusters: 3\n",
      "Estimated number of noise points: 3541\n",
      "Estimated percentage of crime captured: 0.06889297922692611\n",
      "\n",
      "DBSCAN clustering with eps=100m, min_samples=70\n",
      "Estimated number of clusters: 2\n",
      "Estimated number of noise points: 3606\n",
      "Estimated percentage of crime captured: 0.051801209571391005\n",
      "\n",
      "DBSCAN clustering with eps=100m, min_samples=75\n",
      "Estimated number of clusters: 1\n",
      "Estimated number of noise points: 3677\n",
      "Estimated percentage of crime captured: 0.03313173810149882\n",
      "\n",
      "DBSCAN clustering with eps=100m, min_samples=80\n",
      "Estimated number of clusters: 1\n",
      "Estimated number of noise points: 3677\n",
      "Estimated percentage of crime captured: 0.03313173810149882\n",
      "\n",
      "DBSCAN clustering with eps=100m, min_samples=85\n",
      "Estimated number of clusters: 1\n",
      "Estimated number of noise points: 3677\n",
      "Estimated percentage of crime captured: 0.03313173810149882\n",
      "\n",
      "DBSCAN clustering with eps=100m, min_samples=90\n",
      "Estimated number of clusters: 1\n",
      "Estimated number of noise points: 3677\n",
      "Estimated percentage of crime captured: 0.03313173810149882\n",
      "\n",
      "DBSCAN clustering with eps=100m, min_samples=95\n",
      "Estimated number of clusters: 1\n",
      "Estimated number of noise points: 3677\n",
      "Estimated percentage of crime captured: 0.03313173810149882\n",
      "\n",
      "DBSCAN clustering with eps=100m, min_samples=100\n",
      "Estimated number of clusters: 1\n",
      "Estimated number of noise points: 3677\n",
      "Estimated percentage of crime captured: 0.03313173810149882\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=15),\n",
       "  'params': (100, 15),\n",
       "  'num_clusters': 66,\n",
       "  'num_noise': 1937,\n",
       "  'percent_clustered': 0.4906652642650539},\n",
       " {'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=20),\n",
       "  'params': (100, 20),\n",
       "  'num_clusters': 40,\n",
       "  'num_noise': 2373,\n",
       "  'percent_clustered': 0.3760189324217723},\n",
       " {'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=25),\n",
       "  'params': (100, 25),\n",
       "  'num_clusters': 25,\n",
       "  'num_noise': 2700,\n",
       "  'percent_clustered': 0.2900341835393111},\n",
       " {'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=30),\n",
       "  'params': (100, 30),\n",
       "  'num_clusters': 19,\n",
       "  'num_noise': 2857,\n",
       "  'percent_clustered': 0.24875098606363397},\n",
       " {'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=35),\n",
       "  'params': (100, 35),\n",
       "  'num_clusters': 13,\n",
       "  'num_noise': 3051,\n",
       "  'percent_clustered': 0.1977386273994215},\n",
       " {'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=40),\n",
       "  'params': (100, 40),\n",
       "  'num_clusters': 10,\n",
       "  'num_noise': 3165,\n",
       "  'percent_clustered': 0.16776229292663686},\n",
       " {'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=45),\n",
       "  'params': (100, 45),\n",
       "  'num_clusters': 8,\n",
       "  'num_noise': 3249,\n",
       "  'percent_clustered': 0.14567446752563765},\n",
       " {'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=50),\n",
       "  'params': (100, 50),\n",
       "  'num_clusters': 8,\n",
       "  'num_noise': 3249,\n",
       "  'percent_clustered': 0.14567446752563765},\n",
       " {'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=55),\n",
       "  'params': (100, 55),\n",
       "  'num_clusters': 7,\n",
       "  'num_noise': 3299,\n",
       "  'percent_clustered': 0.13252695240599527},\n",
       " {'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=60),\n",
       "  'params': (100, 60),\n",
       "  'num_clusters': 5,\n",
       "  'num_noise': 3415,\n",
       "  'percent_clustered': 0.10202471732842493},\n",
       " {'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=65),\n",
       "  'params': (100, 65),\n",
       "  'num_clusters': 3,\n",
       "  'num_noise': 3541,\n",
       "  'percent_clustered': 0.06889297922692611},\n",
       " {'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=70),\n",
       "  'params': (100, 70),\n",
       "  'num_clusters': 2,\n",
       "  'num_noise': 3606,\n",
       "  'percent_clustered': 0.051801209571391005},\n",
       " {'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=75),\n",
       "  'params': (100, 75),\n",
       "  'num_clusters': 1,\n",
       "  'num_noise': 3677,\n",
       "  'percent_clustered': 0.03313173810149882},\n",
       " {'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=80),\n",
       "  'params': (100, 80),\n",
       "  'num_clusters': 1,\n",
       "  'num_noise': 3677,\n",
       "  'percent_clustered': 0.03313173810149882},\n",
       " {'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=85),\n",
       "  'params': (100, 85),\n",
       "  'num_clusters': 1,\n",
       "  'num_noise': 3677,\n",
       "  'percent_clustered': 0.03313173810149882},\n",
       " {'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=90),\n",
       "  'params': (100, 90),\n",
       "  'num_clusters': 1,\n",
       "  'num_noise': 3677,\n",
       "  'percent_clustered': 0.03313173810149882},\n",
       " {'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=95),\n",
       "  'params': (100, 95),\n",
       "  'num_clusters': 1,\n",
       "  'num_noise': 3677,\n",
       "  'percent_clustered': 0.03313173810149882},\n",
       " {'type': 'DBSCAN',\n",
       "  'model': DBSCAN(eps=1.570718646914388e-05, metric='haversine', min_samples=100),\n",
       "  'params': (100, 100),\n",
       "  'num_clusters': 1,\n",
       "  'num_noise': 3677,\n",
       "  'percent_clustered': 0.03313173810149882}]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscans_df, summaries = run_dbscans(X, cap_hill_23, range(15, 105, 5))\n",
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting time windows\n",
    "1. Need to extract endpoints of the form (start_month, start_year), (end_month, end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2008),\n",
       " (7, 2008),\n",
       " (1, 2009),\n",
       " (7, 2009),\n",
       " (1, 2010),\n",
       " (7, 2010),\n",
       " (1, 2011),\n",
       " (7, 2011),\n",
       " (1, 2012),\n",
       " (7, 2012),\n",
       " (1, 2013),\n",
       " (7, 2013),\n",
       " (1, 2014),\n",
       " (7, 2014),\n",
       " (1, 2015),\n",
       " (7, 2015),\n",
       " (1, 2016),\n",
       " (7, 2016),\n",
       " (1, 2017),\n",
       " (7, 2017),\n",
       " (1, 2018),\n",
       " (7, 2018),\n",
       " (1, 2019),\n",
       " (7, 2019),\n",
       " (1, 2020),\n",
       " (7, 2020),\n",
       " (1, 2021),\n",
       " (7, 2021),\n",
       " (1, 2022),\n",
       " (7, 2022)]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract time window as a series of month, year intervals\n",
    "def months_to_year_month(base_year, months):\n",
    "    year = base_year + int(months / 12)\n",
    "    month = (months % 12)\n",
    "    return month, year\n",
    "\n",
    "\n",
    "def extract_windows(start_year, end_year, length=12, step=6):\n",
    "    \"\"\"Generates a sequence of cuts as a 'sliding time window' \n",
    "    \"\"\"\n",
    "    num_months = (end_year - start_year) * 12\n",
    "    cut_months = range(1, num_months, step)\n",
    "    cuts = [months_to_year_month(2008, cut) for cut in cut_months]\n",
    "    return cuts\n",
    "\n",
    "# Need to join the endpoints into time ranges\n",
    "extract_windows(2008, 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial exploration\n",
    "1. Because we want micro hotspots, we only really have the density params to work with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 66\n",
      "Estimated number of noise points: 1937\n",
      "Estimated percentage of crime captured: 0.4906652642650539\n"
     ]
    }
   ],
   "source": [
    "# Test DBSCAN \n",
    "db = DBSCAN(eps=meters_to_hav(125), min_samples=15, metric=\"haversine\").fit(X)\n",
    "labels_db = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels_db)) - (1 if -1 in labels_db else 0)\n",
    "n_noise_ = list(labels_db).count(-1)\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)\n",
    "print(f\"Estimated percentage of crime captured: {(support - n_noise_) / support}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 67\n",
      "Estimated number of noise points: 1950\n",
      "Estimated percentage of crime captured: 0.4872469103339469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edouas/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_optics.py:992: RuntimeWarning: divide by zero encountered in divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    }
   ],
   "source": [
    "# Test OPTICS\n",
    "op = OPTICS(min_samples=15, max_eps=meters_to_hav(100), xi=0.5, metric=\"haversine\").fit(X)\n",
    "labels_op = op.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels_op)) - (1 if -1 in labels_op else 0)\n",
    "n_noise_ = list(labels_op).count(-1)\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)\n",
    "print(f\"Estimated percentage of crime captured: {(support - n_noise_) / support}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 90\n",
      "Estimated number of noise points: 1193\n",
      "Estimated percentage of crime captured: 0.6863002892453326\n"
     ]
    }
   ],
   "source": [
    "# Test HDBSCAN\n",
    "hdb = HDBSCAN(\n",
    "    min_cluster_size=15,\n",
    "    # min_samples=30,\n",
    "    cluster_selection_epsilon=meters_to_hav(100),\n",
    "    metric=\"haversine\",\n",
    "    store_centers=\"centroid\",\n",
    ").fit(X)\n",
    "labels_hdb = hdb.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels_hdb)) - (1 if -1 in labels_hdb else 0)\n",
    "n_noise_ = list(labels_hdb).count(-1)\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
